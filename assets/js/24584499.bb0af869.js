"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1784],{69910:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2023/10/04/emiquon-preserve","metadata":{"permalink":"/news/2023/10/04/emiquon-preserve","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2023-10-04-emiquon-preserve.md","source":"@site/news/2023-10-04-emiquon-preserve.md","title":"Tower installation with Sage nodes in Emiquon Preserve","description":"2 Sage nodes were deployed in Emiquon Preserve to monitor wildlife and understand conditions of the local environment. The Sage nodes W020 and W01B are equipped with both stationary and pan-tilt-zoom-able cameras and meteorological sensors including dust and weather sensors. The Sage node W01B is the first field-deployed node powered by renewable energe from 8 solar panels. See more in the nature conservancy.","date":"2023-10-04T00:00:00.000Z","formattedDate":"October 4, 2023","tags":[{"label":"wildlife conservancy","permalink":"/news/tags/wildlife-conservancy"},{"label":"environmental science","permalink":"/news/tags/environmental-science"},{"label":"solar-powered","permalink":"/news/tags/solar-powered"}],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Tower installation with Sage nodes in Emiquon Preserve","hide_reading_time":true,"tags":["wildlife conservancy","environmental science","solar-powered"]},"nextItem":{"title":"Scalable AI@Edge at Argonne\'s Advanced Photon Source","permalink":"/news/2023/05/31/scalable-ci-in-aps"}},"content":"2 Sage nodes were deployed in Emiquon Preserve to monitor wildlife and understand conditions of the local environment. The Sage nodes [W020](https://portal.sagecontinuum.org/node/W020) and [W01B](https://portal.sagecontinuum.org/node/W01B) are equipped with both stationary and pan-tilt-zoom-able cameras and meteorological sensors including dust and weather sensors. The Sage node [W01B](https://portal.sagecontinuum.org/node/W01B) is the first field-deployed node powered by renewable energe from 8 solar panels. See more in [the nature conservancy](/partners/the-nature-conservancy)."},{"id":"/2023/05/31/scalable-ci-in-aps","metadata":{"permalink":"/news/2023/05/31/scalable-ci-in-aps","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2023-05-31-scalable-ci-in-aps.md","source":"@site/news/2023-05-31-scalable-ci-in-aps.md","title":"Scalable AI@Edge at Argonne\'s Advanced Photon Source","description":"Earlier this year, Sage computer science researchers and computational scientists from Argonne\'s Advanced Photon Source (APS) collaborated to answer the question: Can edge computing be used in X-ray beamline experiments to process high-volume and fast data streams for real-time decision making?  Read more about the experiment here under Sage Science.","date":"2023-05-31T00:00:00.000Z","formattedDate":"May 31, 2023","tags":[{"label":"edge computing","permalink":"/news/tags/edge-computing"},{"label":"computer science","permalink":"/news/tags/computer-science"},{"label":"computational science","permalink":"/news/tags/computational-science"},{"label":"Argonne APS","permalink":"/news/tags/argonne-aps"},{"label":"Sage science","permalink":"/news/tags/sage-science"}],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Scalable AI@Edge at Argonne\'s Advanced Photon Source","hide_reading_time":true,"tags":["edge computing","computer science","computational science","Argonne APS","Sage science"]},"prevItem":{"title":"Tower installation with Sage nodes in Emiquon Preserve","permalink":"/news/2023/10/04/emiquon-preserve"},"nextItem":{"title":"Sage\'s Scott Collis and Waggle in the News","permalink":"/news/2023/05/05/neiu-crocus-deploy"}},"content":"Earlier this year, Sage computer science researchers and computational scientists from Argonne\'s Advanced Photon Source (APS) collaborated to answer the question: Can edge computing be used in X-ray beamline experiments to process high-volume and fast data streams for real-time decision making?  Read more about the experiment [here](/science/scalable-ci-in-aps) under [Sage Science](/science)."},{"id":"/2023/05/05/neiu-crocus-deploy","metadata":{"permalink":"/news/2023/05/05/neiu-crocus-deploy","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2023-05-05-neiu-crocus-deploy.md","source":"@site/news/2023-05-05-neiu-crocus-deploy.md","title":"Sage\'s Scott Collis and Waggle in the News","description":"Sage\'s Scott Collis and Argonne researchers deploy Waggle nodes to study the impacts of climate change in Chicago.  Read more at Argonne National Laboratory\'s Press Release","date":"2023-05-05T00:00:00.000Z","formattedDate":"May 5, 2023","tags":[{"label":"Waggle","permalink":"/news/tags/waggle"},{"label":"Climate Science","permalink":"/news/tags/climate-science"},{"label":"in the news","permalink":"/news/tags/in-the-news"}],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Sage\'s Scott Collis and Waggle in the News","hide_reading_time":true,"tags":["Waggle","Climate Science","in the news"]},"prevItem":{"title":"Scalable AI@Edge at Argonne\'s Advanced Photon Source","permalink":"/news/2023/05/31/scalable-ci-in-aps"},"nextItem":{"title":"Sage Neon deployment to the Konza LTER site in Kansas","permalink":"/news/sage-neon-deploy-konza"}},"content":"Sage\'s Scott Collis and Argonne researchers deploy Waggle nodes to study the impacts of climate change in Chicago.  Read more at [Argonne National Laboratory\'s Press Release](https://www.anl.gov/article/new-tools-to-combat-chicagos-changing-climate)"},{"id":"sage-neon-deploy-konza","metadata":{"permalink":"/news/sage-neon-deploy-konza","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2022-11-03-sage-neon-deploy.md","source":"@site/news/2022-11-03-sage-neon-deploy.md","title":"Sage Neon deployment to the Konza LTER site in Kansas","description":"In April 2022, 4 Sage nodes (3 Wild Sage Nodes and 1 Blade Node) were deployed with an array of sensors (thermographic camera, air quality sensor, etc.) to collect data to better our understanding of smoke and wildfire detection.","date":"2022-11-03T00:00:00.000Z","formattedDate":"November 3, 2022","tags":[{"label":"node","permalink":"/news/tags/node"},{"label":"deployment","permalink":"/news/tags/deployment"}],"readingTime":0.66,"hasTruncateMarker":true,"authors":[{"name":"Joe Swantek","title":"Software Engineer","imageURL":"https://avatars.githubusercontent.com/u/63811401?v=4Profile_avatar_placeholder_large.png"}],"frontMatter":{"slug":"sage-neon-deploy-konza","title":"Sage Neon deployment to the Konza LTER site in Kansas","author":"Joe Swantek","author_title":"Software Engineer","author_image_url":"https://avatars.githubusercontent.com/u/63811401?v=4Profile_avatar_placeholder_large.png","tags":["node","deployment"]},"prevItem":{"title":"Sage\'s Scott Collis and Waggle in the News","permalink":"/news/2023/05/05/neiu-crocus-deploy"},"nextItem":{"title":"Pedestrian Count for Crosswalk Violations","permalink":"/news/2021/02/12/ped-count-for-cross"}},"content":"<p>In April 2022, 4 Sage nodes (3 <a href=\\"/docs/about/architecture#wild-sage-node-wild-waggle-node\\" target=\\"_blank\\" rel=\\"noopener\\">Wild Sage Nodes</a> and 1 <a href=\\"/docs/about/architecture#blade-node\\" target=\\"_blank\\" rel=\\"noopener\\">Blade Node</a>) were deployed with an array of sensors (thermographic camera, air quality sensor, etc.) to collect data to better our understanding of smoke and wildfire detection.</p>\\n\\n\x3c!--truncate--\x3e\\n\\n<iframe title=\\"Sage NEON deployment to the Konza LTER site in Kansas.\\" src=\\"https://www.youtube.com/embed/GF0jbkMPlTc?feature=oembed\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\" width=\\"100%\\" height=\\"400\\" allowfullscreen=\\"\\" id=\\"fitvid61143\\"></iframe>\\n\\n\\n#### Thermal imaging was used to understand how air temperature can be used to detect smoke and the early warning signs of fire.\\n\\n\\n![Deployed MDP tower](img/sage-neon-deploy/during-burn.png)\\nDeployed MDP tower hosting Sage nodes in the middle of the controlled burn\\n\\n![thermal images](img/sage-neon-deploy/thermal-img.png)\\n<figcaption>Thermal images showing the detected increase in air temperature</figcaption>\\n\\n![dashboard](img/sage-neon-deploy/konza-dash.png)\\n<figcaption>Sage portal website showing data, image and audio feeds from Sage nodes</figcaption>"},{"id":"/2021/02/12/ped-count-for-cross","metadata":{"permalink":"/news/2021/02/12/ped-count-for-cross","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2021-02-12-ped-count-for-cross.md","source":"@site/news/2021-02-12-ped-count-for-cross.md","title":"Pedestrian Count for Crosswalk Violations","description":"Hi, I am Pratool Bharti, an assistant professor in Computer Science department at Northern Illinois University (NIU). Before joining NIU, I worked for 2 years in a Florida based startup as a research and development manager. There, my role was to design and build computer vision and machine learning based yard management system that automatically tracks the vehicles inside a freight yard.  At NIU, I am deeply interested in solving complex real-life problems by employing computer science tools and techniques, especially artificial intelligence and computer vision. While working at Argonne National Lab in summer 2020, I worked on to design and build an AI-enabled computer vision system that counts the pedestrians who violate the crosswalk while crossing the street. The goal of this project is 3-fold; first \u2013 detect every pedestrian in the image, second \u2013 re-identify the pedestrian in successive frames to avoid their recounting, third \u2013 count the pedestrians who do not follow the crosswalk. A sample output image from the project is shown in Figure 1.","date":"2021-02-12T00:00:00.000Z","formattedDate":"February 12, 2021","tags":[{"label":"AI applications","permalink":"/news/tags/ai-applications"},{"label":"NIU","permalink":"/news/tags/niu"}],"readingTime":10.01,"hasTruncateMarker":true,"authors":[{"name":"Pratool Bharti","title":"Assistant Professor, Dept. of Computer Science, Northern Illinois University","url":"https://pratoolbharti.github.io/NIU/","imageURL":"https://pratoolbharti.github.io/NIU/images/profile.png"}],"frontMatter":{"title":"Pedestrian Count for Crosswalk Violations","author":"Pratool Bharti","author_title":"Assistant Professor, Dept. of Computer Science, Northern Illinois University","author_url":"https://pratoolbharti.github.io/NIU/","author_image_url":"https://pratoolbharti.github.io/NIU/images/profile.png","tags":["AI applications","NIU"]},"prevItem":{"title":"Sage Neon deployment to the Konza LTER site in Kansas","permalink":"/news/sage-neon-deploy-konza"},"nextItem":{"title":"Argonne\'s Big Data Camp Goes Virtual","permalink":"/news/big-data"}},"content":"Hi, I am Pratool Bharti, an assistant professor in Computer Science department at Northern Illinois University (NIU). Before joining NIU, I worked for 2 years in a Florida based startup as a research and development manager. There, my role was to design and build computer vision and machine learning based yard management system that automatically tracks the vehicles inside a freight yard. \x3c!-- truncate --\x3e At NIU, I am deeply interested in solving complex real-life problems by employing computer science tools and techniques, especially artificial intelligence and computer vision. While working at Argonne National Lab in summer 2020, I worked on to design and build an AI-enabled computer vision system that counts the pedestrians who violate the crosswalk while crossing the street. The goal of this project is 3-fold; first \u2013 detect every pedestrian in the image, second \u2013 re-identify the pedestrian in successive frames to avoid their recounting, third \u2013 count the pedestrians who do not follow the crosswalk. A sample output image from the project is shown in Figure 1.\\n\\n![sample output image](./img/ped-count-for-cross/Figure-1.png)\\n\\n> Figure 1: A sample output image of pedestrian count project. Green box represents that the pedestrian has taken the crosswalk while crossing the street. White box represents that the pedestrian has not crossed the street yet.\\nMotivation\\n\\nAn accurate and clear information about pedestrian travel patterns is a critical component of transportation planning, management and safety. Sound data on pedestrian system usage is needed for traffic safety, operations, maintenance as well as system user outreach and education.  According to CDC report <sup>[[1]](#references)</sup>, in 2017 alone, 5977 pedestrians were killed in traffic crashes in the United States. That\u2019s about one death every 88 minutes. The broad motivation of this study is to explore the pedestrian travel patterns to understand the contexts in which they violate the traffic rules. To do so, the immediate goal is to count the number of pedestrians who do not follow the crosswalk while crossing the street.\\n\\n## Data Description\\n\\nIn this study, a total of 2,580,468 images were collected by employing a vision camera embedded in an AoT (Array of Things) <sup>[[2]](#references)</sup> node (shown in Fig. 2). The AoT node is installed on a streetlight pole at Northern Illinois University, DeKalb, IL in front of the Computer Science building. The camera captures the image (as shown in Figure 2) at 1 Hz frequency with the resolution of 96 dpi.\\n\\n![aot install](./img/ped-count-for-cross/Figure-2.jpg)\\n\\n> Figure 2: AoT node installed on a light pole at NIU campus\\nApproach\\n\\nIn this section, I present a brief overview of the pedestrians counting process for crosswalk violation. The complete process is divided into 3 sequential sections as shown in Figure 3. First \u2013 detect every pedestrian in the image, second \u2013 re-identify same pedestrian in successive images to avoid their recounting and third \u2013 detect when the pedestrian finished crossing the street. Each part is explained in the following sections.\\n\\n![workflow diagram ](./img/ped-count-for-cross/Figure-3.png)\\n\\n> Figure 3: Workflow diagram for pedestrian crosswalk violation\\nPedestrian Detection\\n\\nThe first step is to detect every pedestrian along with their position in the image. To do so, one approach could be to train a neural network-based pedestrian detection model that identifies and locates the pedestrian in the image. However, this process would require a lot of manual image tagging without getting any new results since several popular pre-trained models are already available that can do a fine job in person detection. These pre-trained models are trained on a popular COCO dataset <sup>[[3]](#references)</sup> which includes more than hundred thousand images. Model accuracy is an important factor here because if it misses any pedestrian in the image then the final pedestrian counting cannot be accurate. To take it into consideration, I selected the Faster R-CNN <sup>[[4]](#references)</sup> based NasNet <sup>[[5]](#references)</sup> object detection model from the TensorFlow model zoo <sup>[[9]](#references)</sup>. Although NasNet model has high latency, it has very good mean average precision value to detect the objects precisely in the image. The images are input to NasNet model and store the prediction results in the XML format. A sample of image and generated XML is shown in Figure 4. XML stores each detected objects\u2019 name and their box coordinates.\\n\\n\\n![output image and xml from NasNet](./img/ped-count-for-cross/Figure-4.png)\\n\\n> Figure 4: Output image and XML generated from NasNet object detection model. Detected objects are boxed in the image.\\nPedestrian Re-identification (ReID)\\n\\nOnce each pedestrian\u2019s position is stored in the XML, the next part is to identify them in successive images to avoid their recounting. In computer vision community, this task is called pedestrian re-identification (ReID) [7]. The idea behind ReID is to find a metrics or representation of a pedestrian in the image that is invariant of different angles, distance, zoom level, etc. Neural networks-based models try to learn local regions (shoes, glasses, hair color, etc.) as well as global full body region (t-shirt and shorts color, design, etc.) features to discriminate the one pedestrian from others. At the end of training, these models aim to generate invariant multi-dimensional features of a pedestrian from different angles, distance, clothes, etc. In this study, I have leveraged a deep learning-based model deep-person-reid [7,8] to generate such features of each pedestrian detected in the frame to compare with the pedestrians from the following frames for re-identification. The model generates 1024-dimensional features for each pedestrian cropped in a rectangular box. The cosine similarity is calculated for feature vectors of one frame against successive frames. Pedestrians are considered same if they have high cosine score, hence, assigned the same pedestrian id. In other cases where cosine similarity is below a pre-defined threshold, both pedestrians are assigned different ids. Low matching score may also happen where pedestrian is partially occluded by a car or another pedestrian in next frame, the similarity score gets very low. To mitigate this issue, the algorithm compared the current frame against last 5 consecutive frames to avoid assigning new id to same pedestrian. Another challenge I faced with the threshold-based matching is when one pedestrian had high similarity scores against multiple pedestrians. To fix this issue, I employed the greedy method in which it ranks each pair according to their similarity score. Based on their ranking, the algorithm picks the top pair and assigns same id to both pedestrians, and subsequently removes other pairs where any one of the pedestrians from the top pair is present. By employing these techniques, I was able to assign unique id to distinct pedestrian.\\n\\n## Pedestrian Count for Crosswalk Violation\\n\\nNow that a unique id is assigned to each distinct pedestrian (barring any errors), the next and the final step in the pipeline is to count the number of pedestrians who have violated the crosswalk while crossing the street. The output of this step will be two metrics for any given time period \u2013 1) number of pedestrians crossed the street and 2) number of pedestrians followed the crosswalk while crossing the street. Subtracting the 2nd metric from 1st one will give the count of crosswalk violations. To compute these metrices, it is important to locate the street and crosswalk in the image. Fortunately, in this case, camera is installed on a fixed streetlight pole which didn\u2019t shake or vibrate significantly due to wind or heavy vehicles. Taking advantage of it, I pre-set the location of crosswalk and street in the image (as shown in Figure 1, the crosswalk is highlighted in yellow and both sides of street in red). While the pre-set of crosswalk is represented in a form of convex polygon, both sides of the street are depicted by two parallel straight lines. These representations helped to determine the location of any pedestrian with respect to the crosswalk and the street. To recall, pedestrian\u2019s location in the image is stored as co-ordinates of 4 corners of a rectangular box. In a 2D image, it is essential to measure each pedestrian\u2019s location by a single (x,y) co-ordinate to make a concrete decision about their position with reference to crosswalk and street. If we observe the Figure 5, the lady is walking on the pavement towards the computer science building, but her head and center of body are still in the street (due to 2D image display) while legs are on the pavement. Similar observations in multiple images made me select the legs position to represent the pedestrian\u2019s location because when pedestrian moves, legs represent the current location in the 2D image.\\n\\n![an detection of crossing](./img/ped-count-for-cross/Figure-5.jpg)\\n\\n> Figure 5 : Our algorithm detects that a person has crossed the street.\\n\\nNow that a pedestrian\u2019s position has been established, I will briefly discuss about the simple rules to determine if a pedestrian has crossed the street and followed/ violated the crosswalk.  A pedestrian is considered to have crossed the street if they are detected on both sides of the street within a fixed time. To recall, the street has been represented by two straight lines, one for each side (as shown in red in Figure 1). The sign of these straight lines against the pedestrian\u2019s coordinates exhibits their position relative to the street. For example, as we see in Figure 6, points A and B are in opposite sides of the straight line which can be verified by putting the value of these points coordinates in the line equation. While the value for point A is -2, for point B it is +3. Opposite signs of both points resemble that they are in opposite sides of the straight line. By similar means, we can compute if the pedestrian has been present to both sides of the street which will confirm that the pedestrian has crossed it. Additionally, to determine if the pedestrian has used the crosswalk, we can similarly verify their positions in the middle of the street. If all of their detected positions are inside the crosswalk polygon, I consider that the pedestrian has used the crosswalk. Using these 2 metrics, the count for crosswalk violations can be easily computed.\\n\\n![determining position](./img/ped-count-for-cross/Figure-6.png)\\n\\n> Figure 6: Determining the position of the points with respect to the straight line\\nFuture Works\\n\\nIn the current study, the implemented system is able to count the pedestrians who violates the crosswalk. Currently, data processing and AI algorithms execute on a server located in computer science building where AoT node periodically stores the images. Many images are lost due to wireless nature of communication. One potential solution can be to implement the algorithms on the AoT node and only transmit the results (instead of images) to server to reduce the overhead on wireless connection significantly. Further, I would like to generalize the system for other sites as well. For that, algorithms have to identify the street and crosswalk automatically in the image.\\n\\n### References\\n\\n1. A CDC Report on pedestrian Safety. (2020, March 06). Retrieved December 22, 2020, from https://www.cdc.gov/transportationsafety/pedestrian_safety/index.html\\n2. P. Beckman, R. Sankaran, C. Catlett, N. Ferrier, and M. Papka, \u201cWaggle: An open sensor platform for edge computing,\u201d in 2016 IEEE Sensors, 2016, pp. 1-3.\\n3. T. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll\xe1r, and C. Zitnick. \u201cMicrosoft coco: Common objects in context.\u201d In European conference on computer vision, pp. 740-755. Springer, Cham, 2014.\\n4. K. He, G. Gkioxari, P. Doll\xe1r, and R. Girshick. \u201cMask r-cnn.\u201d In Proceedings of the IEEE international conference on computer vision, pp. 2961-2969. 2017.\\n5. B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, \u201cLearning transferable architectures for scalable image recognition,\u201d in Proc. IEEE Conf. CVPR, Jun. 2017, pp. 8697\u20138710.\\n6. L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, and Q. Tian. \u201cScalable person re-identification: A benchmark.\u201d In Proceedings of the IEEE international conference on computer vision, pp. 1116-1124. 2015.\\n7. K. Zhou, Y. Yang, A. Cavallaro, and T. Xiang. \u201cOmni-scale feature learning for person re-identification.\u201d In Proceedings of the IEEE International Conference on Computer Vision, pp. 3702-3712. 2019.\\n8. K. Zhou, and T. Xiang. \u201cTorchreid: A library for deep learning person re-identification in pytorch.\u201d arXiv preprint arXiv:1910.10093 (2019).\\n9. Tensorflow. \u201cTensorflow/Models.\u201d GitHub, github.com/tensorflow/models."},{"id":"big-data","metadata":{"permalink":"/news/big-data","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2020-09-02-big-data.md","source":"@site/news/2020-09-02-big-data.md","title":"Argonne\'s Big Data Camp Goes Virtual","description":"For five days last July, fourteen high school students attended a virtual coding camp sponsored by Argonne National Laboratory\u2019s Educational Programs and Outreach and the Argonne Leadership Computing Facility (ALCF), co-taught by laboratory scientists and informal learning educators, and focused on learning techniques for probing and analyzing massive scientific datasets.","date":"2020-09-02T00:00:00.000Z","formattedDate":"September 2, 2020","tags":[{"label":"education","permalink":"/news/tags/education"},{"label":"big data","permalink":"/news/tags/big-data"},{"label":"ALCF","permalink":"/news/tags/alcf"}],"readingTime":5.545,"hasTruncateMarker":true,"authors":[{"name":"Laura Wolf","title":"Coordinating Writer/Editor","url":"https://www.alcf.anl.gov/about/people/laura-wolf","imageURL":"https://upload.wikimedia.org/wikipedia/commons/7/7c/Profile_avatar_placeholder_large.png"}],"frontMatter":{"slug":"big-data","title":"Argonne\'s Big Data Camp Goes Virtual","author":"Laura Wolf","author_title":"Coordinating Writer/Editor","author_url":"https://www.alcf.anl.gov/about/people/laura-wolf","author_image_url":"https://upload.wikimedia.org/wikipedia/commons/7/7c/Profile_avatar_placeholder_large.png","tags":["education","big data","ALCF"]},"prevItem":{"title":"Pedestrian Count for Crosswalk Violations","permalink":"/news/2021/02/12/ped-count-for-cross"},"nextItem":{"title":"Derecho Talk with Scott Collis","permalink":"/news/2020/08/12/derecho-talk-with-scott-collis"}},"content":"For five days last July, fourteen high school students attended a virtual coding camp sponsored by Argonne National Laboratory\u2019s Educational Programs and Outreach and the Argonne Leadership Computing Facility (ALCF), co-taught by laboratory scientists and informal learning educators, and focused on learning techniques for probing and analyzing massive scientific datasets.\\n\\n\x3c!--truncate--\x3e\\n\\nAnd while the COVID-19 pandemic fundamentally changed how these students met, worked, and collaborated over the course of the week, they, and their instructors, found new and creative methods to explore the fascinating world of data science.\\n\\nArgonne\u2019s Big Data Camp is the most recent addition to a growing number of STEM camps for middle school and high school students, offered by the laboratory\u2019s education and outreach department, and aimed at teaching computer science skills and computational thinking. The curriculums are developed and taught by Argonne Educational Programs staff and Argonne scientists. The Big Data Camp curriculum targets juniors and seniors who have programming experience.\\n\\n\u201cWe teach students how researchers produce and process data to better understand a whole range of complex problems from the urgent, like those posed by the current pandemic, to the theoretical, such as the nature of dark matter,\u201d said Michael E. Papka, Argonne senior scientist and camp instructor, who also helped establish the Big Data Camp three years ago. \u201cWe build on their existing programming knowledge and introduced them to some of the same techniques researchers use at the lab to interrogate data and gain new insights.\u201d\\n\\nCampers learned some of the history of data science, such as how physician John Snow first studied patterns in data to map the spread of cholera in mid-nineteenth century Britain, and identified the source of the outbreak. Today\u2019s scientific experimental facilities generate datasets that are vastly larger, and the camp covered contemporary search and analysis techniques such as data visualization methods.\\n\\n### A toolkit for accessing, exploring, and sharing data\\n\\nFor one task, students accessed and explored massive datasets generated by the University of Chicago\u2019s Array of Things (AoT) project, which employs a vast network of computer-embedded \u2018intelligent\u2019 sensors located throughout Chicago to monitor various activities, such as traffic hotspots, and environmental conditions, such as air quality. The AoT project, and its follow-on Software-Defined Sensor Network (SAGE) project, also funded by the National Science Foundation (NSF), will deploy sensor nodes that support machine learning frameworks in three environmental testbeds and one additional urban testbed in the U.S., and in four other countries, to provide even more data\u2014all of which will be open and hosted in the cloud.\\n\\nTo bring order to the massive, amorphous datasets generated by the AoT project, the campers used the open-source web application Jupyter to create documents that contain live code, equations, narrative text, and visualizations\u2014all the essential tools that allowed the campers to analyze the data, but also to share what they learned and communicate it.\\n\\nLater in the week, the campers worked together in small groups to first design a problem and then apply their newly learned programming knowledge and analysis techniques.\\n\\n\u201cCreating their own project allowed them to see the potential challenges in solving big data problems,\u201d said Janet Knowles, a member of ALCF\u2019s visualization team who mentored one of the groups. \u201cI was there to provide guidance, but the kids had to come up with an interesting project with a useful solution.\u201d\\n\\n### Pivoting for the pandemic\\n\\nBy late March, shortly after schools were required to move instruction online because of the COVID-19 pandemic, the organizing team that included Papka, visualization specialists Joe Insley and Silvio Rizzo, operations specialist Ti Leggett, and Argonne Learning Center Lead John Domyancich, needed a strategy to adapt the camp\u2019s hands-on, largely group-oriented lesson plan to a fully-remote experience. They saw several challenges, starting with how to provide students with resources capable of supporting the large data processing needs of the camp, and considered possible workarounds\u2014but never once did they consider cancelling the course.\\n\\nThe team assembled a toolkit that everyone could use to access datasets and to collaborate in live active sessions. Firstly, the campers needed significant data storage and processing power\u2014nearly all of these datasets involved were large: too large to e-mail, and certainly too large for campers to store or process locally. Second, the campers would be working on a variety of devices, from tablets to desktop computers. Lastly, the campers would need a persistent resource for the entire week. The team worked with the developers of Chameleon, a cloud infrastructure service that typically supports the NSF research community, to stand-up a virtual server that could be configured to meet all of the needs of the camp. \u201cChameleon gave us a powerful computing backend, which the students could access and fully utilize from any device,\u201d said Papka.\\n\\nParticipants of the 2020 Big Data Camp seemed to take all the changes in stride. \u201cI learned a lot about data visualization that I hope to apply to projects in the future,\u201d said one camper at the conclusion of the course. \u201cThanks for making Big Data Camp possible and for turning it into such a wonderful online learning experience,\u201d said another.\\n\\n\u201cThe feedback we received from the campers is part of a conversation we\u2019re having now about ways to adapt the camp\u2019s curriculum and develop learning environments to make it accessible to a larger group of students,\u201d said Domyancich.\\n\\nBig Data Camp volunteer instructors and mentors for 2020 included ALCF staff members Michael E. Papka, Joe Insley, Silvio Rizzi, Janet Knowles, Ti Leggett, and Katherine Riley; Argonne Mathematics and Computer Science Director Valerie Taylor; Argonne nuclear engineering postdoctoral student Aaron Oaks; Northern Illinois University Assistant Professor David Koop; former Deputy Associate Laboratory Director for Computing, Environment and Life Sciences Robin Graham; and Argonne Educational Programs and Outreach staff members Kelly Sturner and John Domyancich.\\n\\nThe ALCF is a U.S. Department of Energy (DOE) Office of Science User Facility.\\n\\n### About Argonne\\n\\nArgonne National Laboratory seeks solutions to pressing national problems in science and technology. The nation\u2019s first national laboratory, Argonne conducts leading-edge basic and applied scientific research in virtually every scientific discipline. Argonne researchers work closely with researchers from hundreds of companies, universities, and federal, state and municipal agencies to help them solve their specific problems, advance America\u2019s scientific leadership and prepare the nation for a better future. With employees from more than 60nations, Argonne is managed by UChicago Argonne, LLC for the U.S. Department of Energy\u2019s Office of Science.\\n\\nThe U.S. Department of Energy\u2019s Office of Science is the single largest supporter of basic research in the physical sciences in the United States and is working to address some of the most pressing challenges of our time. For more information, visit https://\u200bener\u200bgy\u200b.gov/\u200bs\u200bc\u200bience."},{"id":"/2020/08/12/derecho-talk-with-scott-collis","metadata":{"permalink":"/news/2020/08/12/derecho-talk-with-scott-collis","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2020-08-12-derecho-talk-with-scott-collis.md","source":"@site/news/2020-08-12-derecho-talk-with-scott-collis.md","title":"Derecho Talk with Scott Collis","description":"Scott Collis, one of the leaders of the Sage project was on local public television August 12th to discuss the devastating derecho storms that hit the Chicago area.","date":"2020-08-12T00:00:00.000Z","formattedDate":"August 12, 2020","tags":[{"label":"talks/presentations","permalink":"/news/tags/talks-presentations"},{"label":"in the news","permalink":"/news/tags/in-the-news"}],"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Derecho Talk with Scott Collis","hide_reading_time":true,"tags":["talks/presentations","in the news"]},"prevItem":{"title":"Argonne\'s Big Data Camp Goes Virtual","permalink":"/news/big-data"},"nextItem":{"title":"Lighting the Way with Software-Defined Radios","permalink":"/news/2020/08/07/lightning-the-way-with-software-defined-radios"}},"content":"[Scott Collis](https://www.anl.gov/profile/scott-m-collis), one of the leaders of the Sage project was on local public television August 12th to discuss the devastating derecho storms that hit the Chicago area.\\n\x3c!-- truncate --\x3e\\n\\nYou can catch the story here: [Chicago Tonight, PBS, Aug 11th, 2020](http://web.archive.org/web/20221128121458/https://www.pbs.org/video/august-11-2020-full-show-vwotwj/)\\n\\nScott\u2019s explanation of the storm start at about minute 19:00"},{"id":"/2020/08/07/lightning-the-way-with-software-defined-radios","metadata":{"permalink":"/news/2020/08/07/lightning-the-way-with-software-defined-radios","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2020-08-07-lightning-the-way-with-software-defined-radios.md","source":"@site/news/2020-08-07-lightning-the-way-with-software-defined-radios.md","title":"Lighting the Way with Software-Defined Radios","description":"Scott Collis and Jim Olds have been exploring how software-defined radios could be used to improved lightning detection.   They have been tinkering at home with several technologies and their hackery was picked up by a few websites:","date":"2020-08-07T00:00:00.000Z","formattedDate":"August 7, 2020","tags":[{"label":"in the news","permalink":"/news/tags/in-the-news"},{"label":"lightning detection","permalink":"/news/tags/lightning-detection"}],"hasTruncateMarker":true,"authors":[{"name":"Scott Collis","url":"https://www.anl.gov/profile/scott-m-collis","imageURL":"https://www.anl.gov/sites/www/files/styles/profile_teaser_square_350px/public/Collis%20Scott%2032749D03_0.jpg?h=d69be872&itok=6k63Thxu"}],"frontMatter":{"title":"Lighting the Way with Software-Defined Radios","hide_reading_time":true,"author":"Scott Collis","author_url":"https://www.anl.gov/profile/scott-m-collis","author_image_url":"https://www.anl.gov/sites/www/files/styles/profile_teaser_square_350px/public/Collis%20Scott%2032749D03_0.jpg?h=d69be872&itok=6k63Thxu","tags":["in the news","lightning detection"]},"prevItem":{"title":"Derecho Talk with Scott Collis","permalink":"/news/2020/08/12/derecho-talk-with-scott-collis"},"nextItem":{"title":"2020 Sage Community Workshop","permalink":"/news/2020/07/29/sage-community-workshop"}},"content":"Scott Collis and Jim Olds have been exploring how software-defined radios could be used to improved lightning detection.  \x3c!-- truncate --\x3e They have been tinkering at home with several technologies and their hackery was picked up by a few websites:\\n\\n[Analyzing Lightning Discharges with an RTL-SDR and the Sage Network](http://web.archive.org/web/20221128111739/https://www.rtl-sdr.com/analyzing-lightning-discharges-with-an-rtl-sdr-and-the-sage-network/)\\n\\n\\n[Lightning Analysis With Your SDR](http://web.archive.org/web/20221128111739/https://hackaday.com/2020/08/07/lightning-analysis-with-your-sdr/)"},{"id":"/2020/07/29/sage-community-workshop","metadata":{"permalink":"/news/2020/07/29/sage-community-workshop","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2020-07-29-sage-community-workshop.md","source":"@site/news/2020-07-29-sage-community-workshop.md","title":"2020 Sage Community Workshop","description":"Workshop Explores Potential of \u2018Smart Sensors\u2019 for Environmental Monitoring","date":"2020-07-29T00:00:00.000Z","formattedDate":"July 29, 2020","tags":[{"label":"workshop","permalink":"/news/tags/workshop"},{"label":"NAISE","permalink":"/news/tags/naise"}],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"2020 Sage Community Workshop","hide_reading_time":true,"tags":["workshop","NAISE"]},"prevItem":{"title":"Lighting the Way with Software-Defined Radios","permalink":"/news/2020/08/07/lightning-the-way-with-software-defined-radios"},"nextItem":{"title":"World Watchers","permalink":"/news/2020/07/28/world-watchers"}},"content":"## [Workshop Explores Potential of \u2018Smart Sensors\u2019 for Environmental Monitoring](https://www.mccormick.northwestern.edu/news/articles/2020/05/workshop-explores-potential-of-smart-sensors-for-environmental-monitoring.html)\\n\\nHeld on the May 11-12, the virtual workshop brought together researchers and scientists to discuss progress on a Northwestern-led project, called SAGE, to develop machine learning-based sensors for environmental monitoring.  [Read more at NAISE...](https://www.mccormick.northwestern.edu/news/articles/2020/05/workshop-explores-potential-of-smart-sensors-for-environmental-monitoring.html)\\n\\nIncluded here is the agenda of the workshop with links to the presentation slides:\\n\\n[View the Sage Community Workshop Agenda](./workshop-pdfs/2020-sage-community-workshop.pdf)"},{"id":"/2020/07/28/world-watchers","metadata":{"permalink":"/news/2020/07/28/world-watchers","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2020-07-28-world-watchers.md","source":"@site/news/2020-07-28-world-watchers.md","title":"World Watchers","description":"Led by investigators at the Northwestern-Argonne Institute of Science and Engineering, researchers are designing a smart new way to monitor our surroundings, from natural ecosystems to urban infrastructure.  Read more at NAISE Research News...","date":"2020-07-28T00:00:00.000Z","formattedDate":"July 28, 2020","tags":[{"label":"in the news","permalink":"/news/tags/in-the-news"},{"label":"NAISE","permalink":"/news/tags/naise"}],"hasTruncateMarker":false,"authors":[],"frontMatter":{"hide_reading_time":true,"tags":["in the news","NAISE"]},"prevItem":{"title":"2020 Sage Community Workshop","permalink":"/news/2020/07/29/sage-community-workshop"},"nextItem":{"title":"2019 Sage AI@Edge Science Workshop","permalink":"/news/2020/07/27/sage-ai-at-edge-workshop"}},"content":"Led by investigators at the Northwestern-Argonne Institute of Science and Engineering, researchers are designing a smart new way to monitor our surroundings, from natural ecosystems to urban infrastructure.  [Read more at NAISE Research News...](https://www.research.northwestern.edu/world-watchers/)"},{"id":"/2020/07/27/sage-ai-at-edge-workshop","metadata":{"permalink":"/news/2020/07/27/sage-ai-at-edge-workshop","editUrl":"https://github.com/waggle-sensor/sage-website/edit/main/news/2020-07-27-sage-ai-at-edge-workshop.md","source":"@site/news/2020-07-27-sage-ai-at-edge-workshop.md","title":"2019 Sage AI@Edge Science Workshop","description":"View the Full Summary and Agenda","date":"2020-07-27T00:00:00.000Z","formattedDate":"July 27, 2020","tags":[{"label":"workshop","permalink":"/news/tags/workshop"},{"label":"NAISE","permalink":"/news/tags/naise"}],"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"2019 Sage AI@Edge Science Workshop","hide_reading_time":true,"tags":["workshop","NAISE"]},"prevItem":{"title":"World Watchers","permalink":"/news/2020/07/28/world-watchers"}},"content":"[View the Full Summary and Agenda](./workshop-pdfs/2019-Sage-AI-at-the-EdgeScienceWorkshop.pdf)"}]}')}}]);